{
  "num_agents": 7,
  "train_length": 1500000,
  "ending_eval_trials": 100,
  "eval_frequency": 0,
  "intermediate_eval_trials": 25,
  "policy_algo_sb3_contrib": false,
  "policy_algo_name": "PPO",
  "policy_name": "MlpPolicy",
  "policy_algo_kwargs": {"n_steps":  4096},
  "monitor": true,

  "experiment_name": "exp2",

  "run_name": "11_20_22__repro4/ppo",
  "run_type": "AO",
  "device": "cuda:1",

  "other_velocities_obs": true,
  "agent_velocity_obs": true,

  "agent_velocity_ignore_theta": false,
  "other_velocities_ignore_theta": false,
  "other_poses_ignore_theta": false,
  "agent_pose_ignore_theta": false,

  "entropy_constant_penalty": -100000,
  "entropy_constant_penalty_only_those_that_did_not_finish": true
}